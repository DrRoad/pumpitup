{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pump it Up: Data Mining the Water Table\n",
    "\n",
    "By: [Ville Heilala](https://heila.la)\n",
    "\n",
    "Datasource: http://taarifa.org/, http://maji.go.tz/, https://www.drivendata.org\n",
    "\n",
    "Goal is to predict the operating condition of a waterpoint for each record in the dataset.\n",
    "\n",
    "## Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version 3.6.0 |Anaconda 4.3.1 (64-bit)| (default, Dec 23 2016, 12:22:00) \n",
      "[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]\n",
      "Pandas version 0.19.2\n",
      "Matplotlib version 2.0.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "%matplotlib inline\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "print('Python version ' + sys.version)\n",
    "print('Pandas version ' + pd.__version__)\n",
    "print('Matplotlib version ' + matplotlib.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "######################\n",
    "# Load data\n",
    "##################################################################\n",
    "\n",
    "# Read data\n",
    "train_values = pd.read_csv(\"/train_values.csv\")\n",
    "train_labels = pd.read_csv(\"/train_labels.csv\")\n",
    "test_values = pd.read_csv(\"/test_values.csv\")\n",
    "\n",
    "# Add binary variables for train set and test values\n",
    "train_values[\"train\"] = True\n",
    "test_values[\"test\"] = True\n",
    "\n",
    "# Merge train values and test values\n",
    "data = pd.concat([train_values, test_values], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from math import log\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import DBSCAN\n",
    "import geocoder\n",
    "\n",
    "# latitude, longitude: round\n",
    "cols = [\"latitude\",\n",
    "        \"longitude\"]\n",
    "\n",
    "for col in cols:\n",
    "    data[col] = data[col].map(lambda x: round(x, 7))\n",
    "    data[col] = data[col].replace(to_replace=-0.0, value=0)\n",
    "\n",
    "# Get missing latitude and longitude values\n",
    "for lga in data[(data.latitude == 0) | (data.longitude == 0)][\"lga\"].unique():\n",
    "    g = geocoder.google(lga)\n",
    "    data.loc[data.lga == lga, \"latitude\"] = g.latlng[0]\n",
    "    data.loc[data.lga == lga, \"longitude\"] = g.latlng[1]\n",
    "\n",
    "# Get missing gps_height values\n",
    "heights = pd.read_csv(\"heights.csv\")\n",
    "heights = pd.Series(heights.gps_height.values, index=heights.id).to_dict()\n",
    "for key in heights.keys():\n",
    "    data.loc[data.id == key, \"gps_height\"] = heights[key]\n",
    "    \n",
    "# Shorten and combine\n",
    "cols = [[\"installer\", 3, 500],\n",
    "        [\"funder\", 3, 50],\n",
    "        [\"subvillage\", 4, 300],\n",
    "        [\"scheme_name\", 5, 300]]\n",
    "combined = \"oth\"\n",
    "\n",
    "for col, chars, treshold in cols:\n",
    "    # Missing values to combined group\n",
    "    data.loc[data[col].isnull() | data[col].isin([\"0\", \"-\", \"_\"]), col] = col + \"_\" + combined\n",
    "    # Lowercase and shorten\n",
    "    data[col] = data[col].map(lambda x: x[:chars].lower())\n",
    "    # Combine lower than treshold\n",
    "    data.loc[data[col].isin(data[col].value_counts()[data[col].value_counts() < treshold].index), col] = col + \"_\" + combined\n",
    "\n",
    "drop = [\"date_recorded\",\n",
    "        \"recorded_by\",\n",
    "        \"ward\",\n",
    "        \"wpt_name\"]\n",
    "data.drop(drop, axis=1, inplace=True)\n",
    "\n",
    "data[\"amount_tsh\"] = data[\"amount_tsh\"].apply(lambda x: log(round(x)) if round(x) > 0 else 0)\n",
    "data[\"population\"] = data[\"population\"].apply(lambda x: log(x) if x > 0 else 0)\n",
    "\n",
    "# latitude, longitude: round\n",
    "cols = [\"latitude\",\n",
    "        \"longitude\"]\n",
    "\n",
    "for col in cols:\n",
    "    data[col] = data[col].map(lambda x: round(x, 6))\n",
    "    data[col] = data[col].replace(to_replace=-0.0, value=0)\n",
    "\n",
    "# DBSCAN\n",
    "db = DBSCAN(eps=0.2, min_samples=200)\n",
    "data[\"loc_clust\"] = db.fit_predict(data[[\"latitude\", \"longitude\"]])\n",
    "    \n",
    "data[\"district_code\"] = data[\"district_code\"].map(lambda x: str(x))\n",
    "data[\"construction_year\"] = data[\"construction_year\"].map(lambda x: str(x))\n",
    "data[\"region_code\"] = data[\"region_code\"].map(lambda x: str(x))\n",
    "data[\"loc_clust\"] = data[\"loc_clust\"].map(lambda x: str(x))\n",
    "data[\"num_private\"] = data[\"num_private\"].map(lambda x: str(x))\n",
    "\n",
    "normalize = ['gps_height',\n",
    "             \"amount_tsh\",\n",
    "             \"population\",\n",
    "             \"latitude\",\n",
    "             \"longitude\"]\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "for n in normalize:\n",
    "    rescaledX = scaler.fit_transform(data[[n]])\n",
    "    data[n] = rescaledX\n",
    "    \n",
    "dummify = ['basin',\n",
    "          'construction_year',\n",
    "          'district_code',\n",
    "          'extraction_type',\n",
    "          'extraction_type_class',\n",
    "          'extraction_type_group',\n",
    "          'funder',\n",
    "          'installer',\n",
    "          'lga',\n",
    "          'management',\n",
    "          'management_group',\n",
    "          'num_private',\n",
    "          'payment',\n",
    "          'payment_type',\n",
    "          'permit',\n",
    "          'public_meeting',\n",
    "          'quality_group',\n",
    "          'quantity',\n",
    "          'quantity_group',\n",
    "          'region',\n",
    "          'region_code',\n",
    "          'scheme_management',\n",
    "          'scheme_name',\n",
    "          'source',\n",
    "          'source_class',\n",
    "          'source_type',\n",
    "          'subvillage',\n",
    "          'water_quality',\n",
    "          'waterpoint_type',\n",
    "          'waterpoint_type_group',\n",
    "          'loc_clust']\n",
    "    \n",
    "final = pd.get_dummies(data[dummify], dummy_na = True)\n",
    "conc = [c for c in list(data) if c not in dummify]\n",
    "final = pd.concat([data[conc], final], axis = 1)\n",
    "\n",
    "# Subset train values\n",
    "train_values = final[final[\"train\"] == True]\n",
    "# Merge train labels\n",
    "train_values = pd.merge(train_values, train_labels, on=\"id\")\n",
    "\n",
    "# Subset test values\n",
    "test_values = final[final[\"test\"] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59400, 750)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(14850, 749)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_values.drop(\"train\", axis=1, inplace=True)\n",
    "train_values.shape\n",
    "test_values.drop(\"test\", axis=1, inplace=True)\n",
    "test_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_values.to_csv(\"/train_values_processed.csv\", index = False)\n",
    "test_values.to_csv(\"/test_values_processed.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
